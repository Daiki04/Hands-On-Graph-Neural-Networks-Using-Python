{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qs9wmH6Jwt5"
      },
      "source": [
        "# Predicting Links with Graph Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6muoc6CEld7m",
        "outputId": "8e544430-ab0f-475f-eb1d-6b0e302c8b4d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "!pip install -q torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-{torch.__version__}.html"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Graph Autoencoder (VAE) and Variational Graph Autoencoder (VGAE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgqVUSiulquq",
        "outputId": "96b273c1-9832-47e0-bde2-bc8d764c5e22"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.NormalizeFeatures(),\n",
        "    T.ToDevice(device),\n",
        "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True, split_labels=True, add_negative_train_samples=False),\n",
        "])\n",
        "\n",
        "dataset = Planetoid('.', name='Cora', transform=transform)\n",
        "\n",
        "train_data, val_data, test_data = dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Hc0ZiEn1lqkq"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GCNConv, VGAE\n",
        "\n",
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, dim_in, dim_out):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(dim_in, 2 * dim_out)\n",
        "        self.conv_mu = GCNConv(2 * dim_out, dim_out)\n",
        "        self.conv_logstd = GCNConv(2 * dim_out, dim_out)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaKaQxpYmC_5",
        "outputId": "4af5b67c-a3e5-4220-9ab9-29d3c2bed6fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  0 | Loss: 3.5030 | Val AUC: 0.6891 | Val AP: 0.7247\n",
            "Epoch 50 | Loss: 1.3045 | Val AUC: 0.6574 | Val AP: 0.7013\n",
            "Epoch 100 | Loss: 1.1622 | Val AUC: 0.7604 | Val AP: 0.7737\n",
            "Epoch 150 | Loss: 1.0805 | Val AUC: 0.7811 | Val AP: 0.7875\n",
            "Epoch 200 | Loss: 0.9752 | Val AUC: 0.8937 | Val AP: 0.8934\n",
            "Epoch 250 | Loss: 0.9659 | Val AUC: 0.8999 | Val AP: 0.9038\n",
            "Epoch 300 | Loss: 0.9361 | Val AUC: 0.9038 | Val AP: 0.9085\n"
          ]
        }
      ],
      "source": [
        "model = VGAE(Encoder(dataset.num_features, 16)).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model.encode(train_data.x, train_data.edge_index)\n",
        "    loss = model.recon_loss(z, train_data.pos_edge_label_index) + (1 / train_data.num_nodes) * model.kl_loss()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    z = model.encode(data.x, data.edge_index)\n",
        "    return model.test(z, data.pos_edge_label_index, data.neg_edge_label_index)\n",
        "\n",
        "for epoch in range(301):\n",
        "    loss = train()\n",
        "    val_auc, val_ap = test(test_data)\n",
        "    if epoch % 50 == 0:\n",
        "        print(f'Epoch {epoch:>2} | Loss: {loss:.4f} | Val AUC: {val_auc:.4f} | Val AP: {val_ap:.4f}') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8219, 0.3609, 0.6127,  ..., 0.6082, 0.8506, 0.8055],\n",
              "        [0.3609, 0.9065, 0.8642,  ..., 0.4280, 0.5970, 0.5648],\n",
              "        [0.6127, 0.8642, 0.8959,  ..., 0.4919, 0.8294, 0.7752],\n",
              "        ...,\n",
              "        [0.6082, 0.4280, 0.4919,  ..., 0.6012, 0.6150, 0.5900],\n",
              "        [0.8506, 0.5970, 0.8294,  ..., 0.6150, 0.9303, 0.8898],\n",
              "        [0.8055, 0.5648, 0.7752,  ..., 0.5900, 0.8898, 0.8438]],\n",
              "       device='cuda:0', grad_fn=<SigmoidBackward0>)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z = model.encode(test_data.x, test_data.edge_index) \n",
        "Ahat = torch.sigmoid(z @ z.T)\n",
        "Ahat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6_nTmTtbDTR",
        "outputId": "f6025b91-9199-412b-94a7-50f066c91dc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.9165, 0.8298, 0.9254, 0.5981, 0.9876, 0.9603, 0.9712, 0.9983, 0.8475,\n",
              "        0.9951, 0.9982, 0.7230, 0.9018, 0.8483, 0.9946, 0.9462, 0.9963, 0.9903,\n",
              "        1.0000, 0.9965, 0.9981, 0.9994, 0.9611, 0.9707, 0.6260, 0.7366, 0.9968,\n",
              "        0.9239, 0.9674, 0.9983, 0.4993, 0.9964, 0.9910, 0.6425, 0.9964, 0.9894,\n",
              "        0.8890, 0.6046, 0.6132, 0.9974, 0.9027, 0.9617, 0.9945, 0.9920, 0.9872,\n",
              "        0.9669, 0.9903, 0.9374, 0.9952, 0.9998, 0.9951, 0.9368, 0.9804, 0.9715,\n",
              "        0.9159, 0.8235, 0.9775, 0.7406, 0.9910, 0.9983, 0.9349, 0.7455, 0.9966,\n",
              "        0.9886, 0.9994, 0.5923, 0.7696, 0.8330, 0.6700, 0.8210, 0.9737, 0.9904,\n",
              "        0.8955, 0.9301, 0.9238, 0.9653, 0.9980, 0.9720, 0.7922, 0.9462, 0.9749,\n",
              "        0.9525, 0.9997, 0.8246, 0.8182, 0.9983, 0.9984, 0.6248, 0.9507, 0.9751,\n",
              "        0.7901, 0.9213, 0.6093, 0.9700, 0.9999, 0.9079, 0.9725, 0.8812, 0.9616,\n",
              "        0.9531, 0.9987, 0.9355, 0.9219, 0.6517, 0.8599, 0.6825, 0.8024, 0.9833,\n",
              "        0.8606, 0.9638, 0.9090, 0.8912, 0.8594, 0.6234, 0.6953, 0.9718, 0.9828,\n",
              "        0.5147, 1.0000, 0.4691, 0.9929, 0.8126, 0.9988, 0.9455, 0.9291, 0.9266,\n",
              "        0.9398, 0.7272, 0.7451, 0.5121, 0.9775, 0.9350, 0.9992, 0.9714, 0.9857,\n",
              "        0.9050, 0.9993, 0.8514, 0.9420, 0.9165, 0.9049, 0.8824, 0.9619, 0.9974,\n",
              "        0.8866, 0.8365, 0.9834, 0.7420, 0.8949, 0.9750, 0.8816, 0.9986, 0.6813,\n",
              "        0.9995, 0.9530, 0.8592, 0.5689, 0.9974, 0.9260, 0.9500, 0.9605, 0.9412,\n",
              "        0.9992, 0.8711, 0.8336, 0.8662, 0.9917, 0.9245, 0.9716, 0.8597, 0.9908,\n",
              "        0.9629, 0.9402, 0.8139, 0.9733, 1.0000, 0.8869, 0.9955, 0.9973, 0.9999,\n",
              "        0.9120, 0.8293, 0.6999, 0.6609, 0.7220, 0.9979, 0.8642, 0.6724, 0.9911,\n",
              "        0.9978, 0.9983, 1.0000, 0.8501, 0.9557, 0.6668, 0.9953, 0.9962, 1.0000,\n",
              "        0.9988, 0.9839, 0.8567, 1.0000, 0.5992, 0.9986, 0.9482, 0.9752, 0.5925,\n",
              "        0.9794, 0.9984, 0.8147, 0.9143, 0.9771, 0.9944, 1.0000, 0.9984, 0.9922,\n",
              "        0.7641, 0.9989, 0.9561, 0.9915, 0.8596, 0.8415, 0.8337, 0.9805, 0.6519,\n",
              "        0.8583, 0.6868, 0.9588, 0.9935, 0.9548, 0.9639, 0.9791, 0.9935, 0.9421,\n",
              "        0.9462, 0.8861, 0.9502, 0.9537, 0.9966, 0.8738, 0.9819, 0.9332, 0.6911,\n",
              "        0.5609, 0.9644, 0.9072, 0.9189, 0.7084, 0.9951, 0.9974, 0.9983, 0.8821,\n",
              "        0.9974, 0.9938, 0.9953, 0.6919, 0.9910, 0.9594, 0.9815, 0.9675, 0.9553,\n",
              "        0.9073, 0.9991, 0.9895, 0.7956, 0.9709, 0.9382, 0.9668, 0.8810, 0.9968,\n",
              "        0.9996, 0.9955, 0.9952, 0.9999, 0.8875, 0.9110, 0.9428, 0.8782, 0.9696,\n",
              "        0.9809, 0.6361, 1.0000, 0.9106, 0.5384, 0.9999, 0.9995, 0.9870, 0.9985,\n",
              "        0.9823, 0.8828, 0.9981, 0.9986, 0.8163, 0.9985, 0.9305, 0.9504, 0.9780,\n",
              "        0.9974, 0.9721, 0.9780, 0.9924, 0.8801, 0.8615, 0.5563, 0.9982, 0.9510,\n",
              "        0.9452, 0.8508, 0.9992, 0.9535, 0.9959, 0.9260, 0.9752, 0.8017, 0.9984,\n",
              "        0.9900, 0.9999, 0.9982, 0.8964, 0.9992, 0.5445, 0.9668, 0.9998, 0.9996,\n",
              "        0.6004, 0.6307, 0.9561, 0.6923, 0.9915, 0.9961, 0.9984, 0.9970, 0.9936,\n",
              "        0.9482, 0.8943, 0.9992, 0.9528, 0.9997, 0.8591, 1.0000, 0.9966, 0.9484,\n",
              "        0.8289, 0.9982, 0.9472, 0.9785, 0.9438, 0.7198, 0.6862, 0.9841, 0.8155,\n",
              "        0.9943, 0.9959, 0.9516, 0.9971, 0.6377, 0.6952, 0.9957, 0.5996, 0.7919,\n",
              "        0.9918, 0.9973, 0.9999, 0.9033, 0.9716, 0.9229, 0.9985, 0.9899, 0.9093,\n",
              "        0.9952, 0.8397, 0.9689, 0.9762, 0.8592, 0.6568, 0.9997, 0.9813, 0.9874,\n",
              "        0.9966, 0.9556, 0.6333, 0.9813, 0.9445, 0.9980, 0.8878, 0.9538, 0.7372,\n",
              "        0.8086, 0.9415, 0.8504, 0.9965, 0.9967, 0.9476, 0.8439, 0.9887, 0.9982,\n",
              "        0.9931, 0.9956, 0.5609, 0.9971, 0.9894, 0.9800, 0.9655, 0.8107, 0.9193,\n",
              "        0.9436, 0.6837, 0.9796, 0.9966, 0.9333, 0.9774, 0.9570, 0.8062, 0.6274,\n",
              "        0.9599, 0.7965, 0.9995, 0.9982, 0.9817, 0.9800, 0.9800, 0.9396, 0.9423,\n",
              "        0.8096, 0.9982, 0.5896, 0.9624, 0.9839, 0.9965, 0.9691, 0.6707, 0.6547,\n",
              "        0.8689, 0.8310, 0.5901, 0.8245, 0.9966, 0.6136, 0.9770, 0.9856, 0.5762,\n",
              "        0.8822, 0.8349, 0.9837, 0.9915, 0.9942, 0.9544, 0.9892, 0.9998, 0.9720,\n",
              "        0.9762, 0.9968, 0.9207, 0.9949, 0.7353, 0.9834, 0.9791, 0.9644, 0.9889,\n",
              "        0.9984, 0.9749, 0.6743, 0.6961, 0.6205, 0.6030, 0.6615, 0.5771, 1.0000,\n",
              "        0.9992, 0.9959, 0.9553, 0.9919, 0.9975, 0.9668, 0.9946, 0.8770, 0.9245,\n",
              "        0.9735, 0.8008, 0.9241, 0.9874, 0.9981, 0.5755, 0.9873, 0.9971, 0.5327,\n",
              "        0.9748, 0.9981, 0.9893, 0.8554, 0.9615, 0.9000, 0.5845, 0.9946, 0.9206,\n",
              "        0.9678, 0.9999, 0.8420, 0.9661, 0.9596, 0.9992, 0.9959, 0.9996, 0.9900,\n",
              "        0.9995, 0.8850, 0.5860, 0.6182, 0.9965, 0.6470, 0.9154, 0.9661, 0.9111,\n",
              "        0.8427, 0.9821, 0.9331, 0.9600, 0.9986, 0.9319, 0.7030, 0.5688, 0.9996,\n",
              "        0.9770, 0.9701, 0.8494, 0.9968, 0.9967], device='cuda:0',\n",
              "       grad_fn=<SigmoidBackward0>)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z = model.encode(test_data.x, test_data.pos_edge_label_index)\n",
        "model.decoder(z, test_data.pos_edge_label_index, sigmoid=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SEAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNNO18ePLd1W",
        "outputId": "c679fa31-3fbd-4971-c127-1079f13c9f04"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from scipy.sparse.csgraph import shortest_path\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Conv1d, MaxPool1d, Linear, Dropout, BCEWithLogitsLoss\n",
        "\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, aggr\n",
        "from torch_geometric.utils import k_hop_subgraph, to_scipy_sparse_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XqlCeawwm0Pp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], pos_edge_label=[4488], pos_edge_label_index=[2, 4488], neg_edge_label=[4488], neg_edge_label_index=[2, 4488])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load Cora dataset\n",
        "transform = RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True, split_labels=True)\n",
        "dataset = Planetoid('.', name='Cora', transform=transform)\n",
        "train_data, val_data, test_data = dataset[0]\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tCSfv3PSMQ-e"
      },
      "outputs": [],
      "source": [
        "def seal_processing(dataset, edge_label_index, y):\n",
        "    data_list = []\n",
        "\n",
        "    for src, dst in edge_label_index.t().tolist():\n",
        "        sub_nodes, sub_edge_index, mapping, _ = k_hop_subgraph([src, dst], 2, dataset.edge_index, relabel_nodes=True)\n",
        "        src, dst = mapping.tolist()\n",
        "\n",
        "        # Remove target link from the subgraph\n",
        "        mask1 = (sub_edge_index[0] != src) | (sub_edge_index[1] != dst)\n",
        "        mask2 = (sub_edge_index[0] != dst) | (sub_edge_index[1] != src)\n",
        "        sub_edge_index = sub_edge_index[:, mask1 & mask2]\n",
        "\n",
        "        # Double-radius node labeling (DRNL)\n",
        "        src, dst = (dst, src) if src > dst else (src, dst)\n",
        "        adj = to_scipy_sparse_matrix(sub_edge_index, num_nodes=sub_nodes.size(0)).tocsr()\n",
        "\n",
        "        idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
        "        adj_wo_src = adj[idx, :][:, idx]\n",
        "\n",
        "        idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
        "        adj_wo_dst = adj[idx, :][:, idx]\n",
        "\n",
        "        # Calculate the distance between every node and the source target node\n",
        "        d_src = shortest_path(adj_wo_dst, directed=False, unweighted=True, indices=src)\n",
        "        d_src = np.insert(d_src, dst, 0, axis=0)\n",
        "        d_src = torch.from_numpy(d_src)\n",
        "\n",
        "        # Calculate the distance between every node and the destination target node\n",
        "        d_dst = shortest_path(adj_wo_src, directed=False, unweighted=True, indices=dst-1)\n",
        "        d_dst = np.insert(d_dst, src, 0, axis=0)\n",
        "        d_dst = torch.from_numpy(d_dst)\n",
        "\n",
        "        # Calculate the label z for each node\n",
        "        dist = d_src + d_dst\n",
        "        z = 1 + torch.min(d_src, d_dst) + dist // 2 * (dist // 2 + dist % 2 - 1)\n",
        "        z[src], z[dst], z[torch.isnan(z)] = 1., 1., 0.\n",
        "        z = z.to(torch.long)\n",
        "\n",
        "        # Concatenate node features and one-hot encoded node labels (with a fixed number of classes)\n",
        "        node_labels = F.one_hot(z, num_classes=200).to(torch.float)\n",
        "        node_emb = dataset.x[sub_nodes]\n",
        "        node_x = torch.cat([node_emb, node_labels], dim=1)\n",
        "\n",
        "        # Create data object\n",
        "        data = Data(x=node_x, z=z, edge_index=sub_edge_index, y=y)\n",
        "        data_list.append(data)\n",
        "\n",
        "    return data_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iPBfn1LLip-",
        "outputId": "afe486e3-ab37-4c05-c56b-d12af68fbc0e"
      },
      "outputs": [],
      "source": [
        "# Enclosing subgraphs extraction\n",
        "train_pos_data_list = seal_processing(train_data, train_data.pos_edge_label_index, 1)\n",
        "train_neg_data_list = seal_processing(train_data, train_data.neg_edge_label_index, 0)\n",
        "\n",
        "val_pos_data_list = seal_processing(val_data, val_data.pos_edge_label_index, 1)\n",
        "val_neg_data_list = seal_processing(val_data, val_data.neg_edge_label_index, 0)\n",
        "\n",
        "test_pos_data_list = seal_processing(test_data, test_data.pos_edge_label_index, 1)\n",
        "test_neg_data_list = seal_processing(test_data, test_data.neg_edge_label_index, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dU_P2-JlR55j"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_pos_data_list + train_neg_data_list\n",
        "val_dataset = val_pos_data_list + val_neg_data_list\n",
        "test_dataset = test_pos_data_list + test_neg_data_list\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OyuODuSqP6iu"
      },
      "outputs": [],
      "source": [
        "class DGCNN(torch.nn.Module):\n",
        "    def __init__(self, dim_in, k=30):\n",
        "        super().__init__()\n",
        "\n",
        "        # GCN layers\n",
        "        self.gcn1 = GCNConv(dim_in, 32)\n",
        "        self.gcn2 = GCNConv(32, 32)\n",
        "        self.gcn3 = GCNConv(32, 32)\n",
        "        self.gcn4 = GCNConv(32, 1)\n",
        "\n",
        "        # Global sort pooling\n",
        "        self.global_pool = aggr.SortAggregation(k=k)\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = Conv1d(1, 16, 97, 97)\n",
        "        self.conv2 = Conv1d(16, 32, 5, 1)\n",
        "        self.maxpool = MaxPool1d(2, 2)\n",
        "\n",
        "        # Dense layers\n",
        "        self.linear1 = Linear(352, 128)\n",
        "        self.dropout = Dropout(0.5)\n",
        "        self.linear2 = Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # 1. Graph Convolutional Layers\n",
        "        h1 = self.gcn1(x, edge_index).tanh()\n",
        "        h2 = self.gcn2(h1, edge_index).tanh()\n",
        "        h3 = self.gcn3(h2, edge_index).tanh()\n",
        "        h4 = self.gcn4(h3, edge_index).tanh()\n",
        "        h = torch.cat([h1, h2, h3, h4], dim=-1)\n",
        "\n",
        "        # 2. Global sort pooling\n",
        "        h = self.global_pool(h, batch)\n",
        "\n",
        "        # 3. Traditional convolutional and dense layers\n",
        "        h = h.view(h.size(0), 1, h.size(-1))\n",
        "        h = self.conv1(h).relu()\n",
        "        h = self.maxpool(h)\n",
        "        h = self.conv2(h).relu()\n",
        "        h = h.view(h.size(0), -1)\n",
        "        h = self.linear1(h).relu()\n",
        "        h = self.dropout(h)\n",
        "        h = self.linear2(h).sigmoid()\n",
        "\n",
        "        return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "kcivDBP4PjDx",
        "outputId": "d733477a-0263-403d-fd1a-6ee3ec8950be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  0 | Loss: 0.6983 | Val AUC: 0.7881 | Val AP: 0.8110\n",
            "Epoch  1 | Loss: 0.6203 | Val AUC: 0.8498 | Val AP: 0.8785\n",
            "Epoch  2 | Loss: 0.5868 | Val AUC: 0.8640 | Val AP: 0.8865\n",
            "Epoch  3 | Loss: 0.5792 | Val AUC: 0.8650 | Val AP: 0.8867\n",
            "Epoch  4 | Loss: 0.5752 | Val AUC: 0.8733 | Val AP: 0.8896\n",
            "Epoch  5 | Loss: 0.5725 | Val AUC: 0.8740 | Val AP: 0.8911\n",
            "Epoch  6 | Loss: 0.5701 | Val AUC: 0.8726 | Val AP: 0.8934\n",
            "Epoch  7 | Loss: 0.5684 | Val AUC: 0.8739 | Val AP: 0.8937\n",
            "Epoch  8 | Loss: 0.5675 | Val AUC: 0.8745 | Val AP: 0.8989\n",
            "Epoch  9 | Loss: 0.5666 | Val AUC: 0.8759 | Val AP: 0.8987\n",
            "Epoch 10 | Loss: 0.5655 | Val AUC: 0.8651 | Val AP: 0.8890\n",
            "Epoch 11 | Loss: 0.5642 | Val AUC: 0.8709 | Val AP: 0.8939\n",
            "Epoch 12 | Loss: 0.5638 | Val AUC: 0.8667 | Val AP: 0.8894\n",
            "Epoch 13 | Loss: 0.5630 | Val AUC: 0.8674 | Val AP: 0.8926\n",
            "Epoch 14 | Loss: 0.5617 | Val AUC: 0.8700 | Val AP: 0.8922\n",
            "Epoch 15 | Loss: 0.5595 | Val AUC: 0.8719 | Val AP: 0.8961\n",
            "Epoch 16 | Loss: 0.5564 | Val AUC: 0.8695 | Val AP: 0.8893\n",
            "Epoch 17 | Loss: 0.5548 | Val AUC: 0.8684 | Val AP: 0.8877\n",
            "Epoch 18 | Loss: 0.5526 | Val AUC: 0.8690 | Val AP: 0.8892\n",
            "Epoch 19 | Loss: 0.5504 | Val AUC: 0.8636 | Val AP: 0.8883\n",
            "Epoch 20 | Loss: 0.5493 | Val AUC: 0.8609 | Val AP: 0.8853\n",
            "Epoch 21 | Loss: 0.5487 | Val AUC: 0.8585 | Val AP: 0.8816\n",
            "Epoch 22 | Loss: 0.5479 | Val AUC: 0.8627 | Val AP: 0.8818\n",
            "Epoch 23 | Loss: 0.5478 | Val AUC: 0.8585 | Val AP: 0.8815\n",
            "Epoch 24 | Loss: 0.5476 | Val AUC: 0.8572 | Val AP: 0.8762\n",
            "Epoch 25 | Loss: 0.5471 | Val AUC: 0.8551 | Val AP: 0.8756\n",
            "Epoch 26 | Loss: 0.5462 | Val AUC: 0.8599 | Val AP: 0.8809\n",
            "Epoch 27 | Loss: 0.5463 | Val AUC: 0.8558 | Val AP: 0.8726\n",
            "Epoch 28 | Loss: 0.5457 | Val AUC: 0.8577 | Val AP: 0.8799\n",
            "Epoch 29 | Loss: 0.5459 | Val AUC: 0.8502 | Val AP: 0.8730\n",
            "Epoch 30 | Loss: 0.5459 | Val AUC: 0.8544 | Val AP: 0.8705\n",
            "Test AUC: 0.8806 | Test AP 0.88\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = DGCNN(train_dataset[0].num_features).to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
        "criterion = BCEWithLogitsLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        loss = criterion(out.view(-1), data.y.to(torch.float))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * data.num_graphs\n",
        "\n",
        "    return total_loss / len(train_dataset)\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    y_pred, y_true = [], []\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        y_pred.append(out.view(-1).cpu())\n",
        "        y_true.append(data.y.view(-1).cpu().to(torch.float))\n",
        "\n",
        "    auc = roc_auc_score(torch.cat(y_true), torch.cat(y_pred))\n",
        "    ap = average_precision_score(torch.cat(y_true), torch.cat(y_pred))\n",
        "\n",
        "    return auc, ap\n",
        "\n",
        "for epoch in range(31):\n",
        "    loss = train()\n",
        "    val_auc, val_ap = test(val_loader)\n",
        "    print(f'Epoch {epoch:>2} | Loss: {loss:.4f} | Val AUC: {val_auc:.4f} | Val AP: {val_ap:.4f}')\n",
        "\n",
        "test_auc, test_ap = test(test_loader)\n",
        "print(f'Test AUC: {test_auc:.4f} | Test AP {test_ap:.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "book",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "3556630122da5213751af4465d61fcf5a52cd22515d400aee51118aaa1721248"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
